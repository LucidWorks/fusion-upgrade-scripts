#!/bin/bash
#
# Run the Spark master apps.

BIN=`dirname "${BASH_SOURCE-$0}"`
SCRIPT=`basename "${BASH_SOURCE-$0}"`
export FUSION_HOME=${FUSION_HOME:-`cd "${BIN}/.."; pwd`}
export SPARK_HOME="${SPARK_HOME:-$FUSION_HOME/spark}"
export APP_BASE="$FUSION_HOME/apps"
export APP_HOME="${SPARK_MASTER_HOME:-${APP_BASE}/spark}"
FUSION_SERVICE_NAME="Fusion Spark Master"
VAR_DIR="$FUSION_HOME/var"
LOG_DIR="$FUSION_HOME/logs/spark-master"
PID_FILE="$VAR_DIR/spark-master.pid"

PORT_NAME='spark-master'

set -e

function do_run() {
  check_java
  JAVA_OPTIONS=("${SPARK_MASTER_JAVA_OPTIONS[@]}")
  extra_java_options
  #printf 'JAVA_OPTION: %s\n' "${JAVA_OPTIONS[@]}"

  cd "$APP_HOME"

  mkdir -p "$LOG_DIR"

  report_port
  write_pid_file

  export SPARK_MASTER_OPTS="${JAVA_OPTIONS[@]} \
    -Dcurator.zk.connect='$FUSION_ZK' \
    -Dcom.lucidworks.apollo.solr.zk.connect='$FUSION_SOLR_ZK' \
    -Dlog4j.configurationFile=file:'$APP_HOME'/log4j2.xml \
    -Dspark.master.port='$SPARK_MASTER_PORT' \
    -Dspark.master.webui.port='$SPARK_MASTER_UI_PORT' \
    -Dapollo.home='$FUSION_HOME' \
    -Dspark.home='$SPARK_HOME'"

  set -x
  exec ${APP_HOME}/bin/spark-master $@

}

. "$FUSION_HOME/bin/common.sh"

main "$@"
